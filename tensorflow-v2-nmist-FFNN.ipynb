{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNUo5k5GxyS3W3Y+ygw/uxv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tensorflow 2: Building a Neural Network"],"metadata":{"id":"dQSPb61GD6h4"}},{"cell_type":"markdown","source":["## DESCRIBE THE PROBLEM"],"metadata":{"id":"aFzQsHWFFG4U"}},{"cell_type":"markdown","source":["##Step 1: Install and load the libraries\n","\n","Install  tensorflow, if not yet installed, and load all the necessary libraries"],"metadata":{"id":"9hP_XtCVEClC"}},{"cell_type":"code","source":["#!pip install tensorflow"],"metadata":{"id":"GToLEx1BELha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"EHsQUTtrEXcO"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzGigBhXDRZb"},"outputs":[],"source":["print(tf.__version__)"]},{"cell_type":"code","source":["import numpy as np\n","import datetime\n","\n","from tensorflow.keras.datasets import fashion_mnist\n","from sklearn.metrics import confusion_matrix\n","\n","import matplotlib.pyplot as plt"],"metadata":{"id":"NhdoV7RIEhHL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Data Preprocessing"],"metadata":{"id":"z5r7s2zYFM2d"}},{"cell_type":"markdown","source":["Load the dataset from the keras ibrary"],"metadata":{"id":"PYTdg74RFUD5"}},{"cell_type":"code","source":["# Load the Fashion NMIST dataset\n","(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"],"metadata":{"id":"x8VzWTIFFD68"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Length train dataset: \", len(X_train))\n","print(\"Length test dataset: \", len(X_test))"],"metadata":{"id":"hZ0RYBzpHJT1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We have to analyze the dimensions or shape of the dataset"],"metadata":{"id":"THfxxoe_HWBe"}},{"cell_type":"code","source":["print(\"Train dataset shape: \",X_train.shape)\n","print(\"Test dataset shape: \",X_test.shape)"],"metadata":{"id":"mOvQdXcpHf1p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Normalize images\n","\n","When working with images, we usually recommend to normalize the dataset in the range [0,1]. You just need to divide each pixel by 255, the max value of a pixel in an image.\n","This action would help our model to train faster and with greater stability.\n"],"metadata":{"id":"i4Bgad1CFrpk"}},{"cell_type":"code","source":["# Normalize train dataset\n","X_train = X_train / 255.0\n","\n","# Normalize test dataset\n","X_test = X_test / 255.0"],"metadata":{"id":"rZwS1MzmFiA4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Show images"],"metadata":{"id":"nnfcna1TUKb1"}},{"cell_type":"markdown","source":["Lets print one image in our dataset"],"metadata":{"id":"L5OrocPnUPR3"}},{"cell_type":"code","source":["plt.figure()\n","plt.imshow(X_train[0])\n","plt.colorbar()\n","plt.grid(False)\n","plt.show()"],"metadata":{"id":"MqoZMM5VUPWz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reshape the dataset"],"metadata":{"id":"gPFwRHsNH0sp"}},{"cell_type":"markdown","source":["We are going to build a fully connected neural network and inputs to this nn must be flatten, then we need to reshape ur dataset"],"metadata":{"id":"5r9VVRNmH3oB"}},{"cell_type":"code","source":["# Reshape the 28x28 matrix of the images to a flatten 784-vector\n","X_train = X_train.reshape(-1, 28*28)\n","X_test = X_test.reshape(-1, 28*28)\n","\n","# Show the new shape\n","print(\"Train dataset shape: \", X_train.shape, \"Test dataset shape: \", X_test.shape)"],"metadata":{"id":"4pKNJq0bG6BI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Build a Fully connected neural network"],"metadata":{"id":"W8Zm49q_JpjR"}},{"cell_type":"markdown","source":["In this experiment, we apply the keras framework to help us to define the network in just a few lines of code.\n","\n","The first action is to create a sequentioal model where layers of nn are connected sequentially."],"metadata":{"id":"o9fQLrvIJ1iZ"}},{"cell_type":"code","source":["model = tf.keras.models.Sequential()"],"metadata":{"id":"KqzA0nrLIgpG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We are going to build a fully connected neural network and the inputs to this nn must be flatten to act as inputs to the neural network. This mean we need to insert a Flatten layer"],"metadata":{"id":"DrX0HbSKRkR5"}},{"cell_type":"code","source":["model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))"],"metadata":{"id":"lLl8AFb-SMAo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we add a Dense layer, fully connected layer, with parameters:\n","\n","- count of neurons: 128\n","- activation function: ReLU\n","- input shape: (784, )\n","\n","Next, we include a dropout layer to reduce overfitting. It is a regularization technique where in every forward pass randomly some neurons are deactivate."],"metadata":{"id":"S5gqj5SUKYbp"}},{"cell_type":"code","source":["# Adding the first dense layer\n","model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n","# Adding a dropout layer\n","model.add(tf.keras.layers.Dropout(0.2))\n"],"metadata":{"id":"TwFLK7yqKXeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Add a second fully connected layer\n","\n","- units: count of classes to predict\n","- activation function: 'softmax'"],"metadata":{"id":"ift2Qjl-MrZm"}},{"cell_type":"code","source":["# Add a second dense layer\n","model.add(tf.keras.layers.Dense(units=10, activation='softmax'))"],"metadata":{"id":"zXASMjrwLRrF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Compile the model"],"metadata":{"id":"AmbjVPbwN1ni"}},{"cell_type":"markdown","source":["- Optimizer: Adam\n","- Loss: Sparse softmax (categorical) crossentropy\n","- Metric: Accuracy"],"metadata":{"id":"DFdeOftyN7IV"}},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","# Show the model structure\n","model.summary()"],"metadata":{"id":"NSKr6UK-NmoP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 5: Train the model"],"metadata":{"id":"gY6bTIHlOcsC"}},{"cell_type":"markdown","source":["In this simple demo, we just train for a few epochs"],"metadata":{"id":"56H7i_BVOhFJ"}},{"cell_type":"code","source":["# Train the model\n","model.fit(X_train, y_train, epochs=5)"],"metadata":{"id":"cJLC4gupOLDt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 6: Evauate the model"],"metadata":{"id":"yxOE9MDuQaY2"}},{"cell_type":"code","source":["# Evaluate the model\n","test_loss, test_accuracy = model.evaluate(X_test, y_test)\n","# Show result\n","print(\"Test accuracy: {}\".format(test_accuracy))"],"metadata":{"id":"CHTWtoX9OrKV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 7: Make predictions"],"metadata":{"id":"hcI-w_myU1Ef"}},{"cell_type":"markdown","source":["Now, it is time to apply the model to the test dataset"],"metadata":{"id":"YI_3vRLeU4oP"}},{"cell_type":"code","source":["# Predict the test dataset\n","Y_pred_prob = model.predict(X_test)"],"metadata":{"id":"P8yiRrFsQqrn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Show one prediction to inspect the values returned, the probability of each class"],"metadata":{"id":"aHuwhJILVetA"}},{"cell_type":"code","source":["# Show probabilities\n","print(Y_pred_prob[0])\n","# Print the class with highest probability\n","print(np.argmax(Y_pred_prob[0]))\n","# Print the true label\n","print(y_test[0])\n"],"metadata":{"id":"n3NHf3h-VxPw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(Y_pred.shape)"],"metadata":{"id":"8AZv-RybVSWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the predicted label for test dataset\n","y_preds= np.argmax(Y_pred_prob, axis=-1)\n","print(y_preds.shape)"],"metadata":{"id":"DYIy-DKIVWq0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Create the confussion matrix"],"metadata":{"id":"OgkDxUcdYnJz"}},{"cell_type":"code","source":["# Calculate the confussion matrix\n","cm = confusion_matrix(y_test, y_preds)\n","print('Confusion Matrix\\n')\n","print(cm)"],"metadata":{"id":"G9p9dsviXPBN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Plotting the confussion matrix will show efficiently how model works. We define a function to plot the matrix"],"metadata":{"id":"1t08_6_bZfnB"}},{"cell_type":"code","source":["# Function to plot the confussion matrix\n","def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n","    plt.show()"],"metadata":{"id":"mW8Pg9_fXTYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a list with the class names\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","# Plot confussion matrix\n","plot_confusion_matrix(cm, class_names)"],"metadata":{"id":"j3sfvhf0X0VG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 8: Save the model"],"metadata":{"id":"POVAKn4idETQ"}},{"cell_type":"markdown","source":["to save our model we make a dir and call the save method"],"metadata":{"id":"kbgmgGMDdJmT"}},{"cell_type":"code","source":["# Save the entire model as a SavedModel.\n","!mkdir -p saved_model\n","# Save the model\n","model.save('saved_model/my_model')"],"metadata":{"id":"0GiUPpYTa9Ov"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Restore the model saved"],"metadata":{"id":"DN1JE3BJde1u"}},{"cell_type":"markdown","source":["When the model is saved using the save method, we can restore and load the model in a new model just calling the load_model. This procedure"],"metadata":{"id":"3Gs5Lz0fdi4W"}},{"cell_type":"code","source":["# Load the saved model\n","new_model = tf.keras.models.load_model('saved_model/my_model')\n","\n","# Check its architecture\n","new_model.summary()"],"metadata":{"id":"KD1PhDLzdWV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the restored model\n","loss, acc = new_model.evaluate(X_test, y_test, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"],"metadata":{"id":"qX7q667SeIjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the predicted label for test dataset\n","y_preds= np.argmax(model.predict(X_test), axis=-1)\n","# Calculate the confussion matrix\n","cm = confusion_matrix(y_test, y_preds)\n","# Plot confussion matrix\n","plot_confusion_matrix(cm, class_names)"],"metadata":{"id":"FGeZAAGxfV0C"},"execution_count":null,"outputs":[]}]}
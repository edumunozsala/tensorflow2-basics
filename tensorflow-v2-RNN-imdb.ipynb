{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyM1eRYcvoPbSnqYDbpRVDp1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Recurrent Neural Network for Language processing"],"metadata":{"id":"2vYiVc-K5U9R"}},{"cell_type":"markdown","source":["## Import and load the libraries"],"metadata":{"id":"QWaIRQD65k1A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3gyyGlX5KNb"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["# Check tensorflow version\n","print(tf.__version__)"],"metadata":{"id":"RlY6KlMC5y7V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import imdb\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","from sklearn.metrics import confusion_matrix"],"metadata":{"id":"TNDsVEH953vk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 1: Data preprocessing"],"metadata":{"id":"GhmBz64w6Jdo"}},{"cell_type":"markdown","source":["We use the imdb datasets in the keras library and the description in the oficial library is:\n","*This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a list of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".*\n","\n","In this simple demo we set the num_words parameter to 20,000 words, this means we only works with the 20,000th most frequent frecuent words. Other words will be included in the OOV, out of vocabulary, bag.\n","\n","We set the parameters and load the dataset:"],"metadata":{"id":"zjh8NeO86Ni4"}},{"cell_type":"code","source":["# Set parameters\n","number_of_words = 20000\n","max_len = 100\n","\n","# Load the dataset\n","(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=number_of_words)"],"metadata":{"id":"9W4CdzZa727t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the shape and inspect values\n","print(\"Train dataset size: \", X_train.shape)\n","print(\"Train label dataset size: \", y_train.shape)\n","\n","print(\"Test dataset size: \", X_test.shape)\n","print(\"Test label dataset size: \", y_test.shape)"],"metadata":{"id":"E7-vrXhj6PaA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["From the shape values we infer that there are 25K items containing a list of values with different lengths. Lets take a closer look:"],"metadata":{"id":"IWsTXdWj9vKs"}},{"cell_type":"code","source":["for i in range(5):\n","  print(\"Length of the list: \", len(X_train[i]))\n","  print(\" Print first five elements in the list: \", X_train[i][:5])\n","\n","  print(\"Length of the list: \", len(X_test[i]))\n","  print(\" Print first five elements in the list: \", X_test[i][:5])"],"metadata":{"id":"K-qkl38K6MdA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Every row starts with 1,the init of sequence token, followed by a list of integer tokens that represent a word in the vocabulary. We retrive the vocabulary dict in order to translate these tokens by building an inverse dict mapping indices to words."],"metadata":{"id":"IKlzgV6_-Kno"}},{"cell_type":"code","source":["# Use the default parameters to keras.datasets.imdb.load_data\n","start_char = 1\n","oov_char = 2\n","index_from = 3\n","\n","# Retrieve the word index file mapping words to indices\n","word_index = tf.keras.datasets.imdb.get_word_index()\n","# Reverse the word index to obtain a dict mapping indices to words\n","# And add `index_from` to indices to sync with `x_train`\n","inverted_word_index = dict(\n","    (i + index_from, word) for (word, i) in word_index.items()\n",")\n","# Update `inverted_word_index` to include `start_char` and `oov_char`\n","inverted_word_index[start_char] = \"[START]\"\n","inverted_word_index[oov_char] = \"[OOV]\""],"metadata":{"id":"YvSaL5wF-xgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract five elements\n","for i in range(5):\n","  print(\"Length of the list: \", len(X_train[i]))\n","  print(\" Print first five elements in the list: \", \" \".join(inverted_word_index[j] for j in X_train[i][:10]))"],"metadata":{"id":"vjDFrsE46Evk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next we must truncate or pad the sequences, we need to work with sequences with equal length"],"metadata":{"id":"ad_Jz1xH_9iY"}},{"cell_type":"code","source":["# Padding the sequences in the datasets\n","X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n","X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)\n","\n","# Check the length of the sequences\n","for i in range(5):\n","  # Print length in X_train\n","  print(\"Length of the X_train list: \", len(X_train[i]))\n","  # Print length in X_test\n","  print(\"Length of the X_train list: \", len(X_test[i]))\n"],"metadata":{"id":"p50RDE6sANy4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 2: Build the RNN"],"metadata":{"id":"mtmxYo8qCw47"}},{"cell_type":"markdown","source":["We build a simple RNN containing three layers:\n","- Embedding layer: with a vocabulary size of 20,000, same number as we used before, and an embedding size of 128.\n","- An LSTM layer: with 128 units and activation function is tanh\n","- An final Dense layer with just 1 output using sigmoid activation\n"],"metadata":{"id":"TexfSw4zC7rB"}},{"cell_type":"code","source":["# Set parameters\n","vocab_size=number_of_words\n","embed_size=128\n","lstm_units=128"],"metadata":{"id":"2J2eBzLoD0NR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a squential network\n","model = tf.keras.Sequential()\n","# Add the embedding layer\n","model.add(tf.keras.layers.Embedding(vocab_size, embed_size, input_shape=(X_train.shape[1],)))\n","# Add the LSTM layer\n","model.add(tf.keras.layers.LSTM(units=lstm_units, activation='tanh'))\n","# Add the dense layer\n","model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"metadata":{"id":"oCcVdzaxDrBy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n","# Show summary\n","model.summary()"],"metadata":{"id":"jEsTH8Ir5_fo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 3: Train the model"],"metadata":{"id":"FwjokWmOF3Dn"}},{"cell_type":"markdown","source":["This time we do not use a validation dataset during training, later we check the performance of the model on the test dataset"],"metadata":{"id":"3FEtHgoKGFqc"}},{"cell_type":"code","source":["history = model.fit(X_train, y_train, epochs=3, batch_size=128)"],"metadata":{"id":"6IaP1_r-F5wl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 4: Evaluate the model"],"metadata":{"id":"OI2lc9x6IgHv"}},{"cell_type":"code","source":["plt.plot(history.history['accuracy'], label='accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.ylim([0.5, 1])\n","plt.legend(loc='lower right')\n","\n","# Calculate the accuracy for thre test dataset\n","test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n","# Print the final accuracy\n","print('Test Accuracy: ',test_acc)"],"metadata":{"id":"Hd4j9MfV5iHw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 5: Make predictions"],"metadata":{"id":"9MLqqTXxJkpl"}},{"cell_type":"code","source":["# Make prediction on test dataset\n","predictions = model.predict(X_test)\n","# Show predictions shape\n","print(' Prediction shape', predictions.shape)"],"metadata":{"id":"z7gun8X5I_sB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lets check oputput values:"],"metadata":{"id":"pAGNeC2MKI1d"}},{"cell_type":"code","source":["print(predictions[:5])"],"metadata":{"id":"inf7WJ76JwLl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Convert the probability to a label"],"metadata":{"id":"Dy9TX1JSLAWC"}},{"cell_type":"code","source":["# If threshold is 0.5\n","y_preds = predictions > 0.5\n","# Show the labels\n","print(y_preds[:5])"],"metadata":{"id":"9YbW0kkILFLn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Plot the Confussion matrix"],"metadata":{"id":"CZvmdpGdLk2Q"}},{"cell_type":"code","source":["# Calculate the confussion matrix\n","cm = confusion_matrix(y_test, y_preds)\n","print('Confusion Matrix\\n')\n","print(cm)"],"metadata":{"id":"YHmVMuGZKPjh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Build a function to plot the confussion matrix"],"metadata":{"id":"0tFs9HMDLycC"}},{"cell_type":"code","source":["# Function to plot the confussion matrix\n","def plot_confusion_matrix(cm,\n","                          target_names,\n","                          title='Confusion matrix',\n","                          cmap=None,\n","                          normalize=True):\n","    \"\"\"\n","    given a sklearn confusion matrix (cm), make a nice plot\n","\n","    Arguments\n","    ---------\n","    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n","\n","    target_names: given classification classes such as [0, 1, 2]\n","                  the class names, for example: ['high', 'medium', 'low']\n","\n","    title:        the text to display at the top of the matrix\n","\n","    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n","                  see http://matplotlib.org/examples/color/colormaps_reference.html\n","                  plt.get_cmap('jet') or plt.cm.Blues\n","\n","    normalize:    If False, plot the raw numbers\n","                  If True, plot the proportions\n","\n","    Usage\n","    -----\n","    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n","                                                              # sklearn.metrics.confusion_matrix\n","                          normalize    = True,                # show proportions\n","                          target_names = y_labels_vals,       # list of names of the classes\n","                          title        = best_estimator_name) # title of graph\n","\n","    Citiation\n","    ---------\n","    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n","\n","    \"\"\"\n","    import matplotlib.pyplot as plt\n","    import numpy as np\n","    import itertools\n","\n","    accuracy = np.trace(cm) / float(np.sum(cm))\n","    misclass = 1 - accuracy\n","\n","    if cmap is None:\n","        cmap = plt.get_cmap('Blues')\n","\n","    plt.figure(figsize=(8, 6))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","\n","    if target_names is not None:\n","        tick_marks = np.arange(len(target_names))\n","        plt.xticks(tick_marks, target_names, rotation=45)\n","        plt.yticks(tick_marks, target_names)\n","\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","\n","    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        if normalize:\n","            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","        else:\n","            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n","                     horizontalalignment=\"center\",\n","                     color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(accuracy, misclass))\n","    plt.show()"],"metadata":{"id":"KornPZviLtF6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the class names\n","class_names = ['Negative', 'Positive']\n","# Plot confussion matrix\n","plot_confusion_matrix(cm, class_names)"],"metadata":{"id":"I0fbZKxRL2DO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Step 8: Save the model"],"metadata":{"id":"POVAKn4idETQ"}},{"cell_type":"markdown","source":["to save our model we make a dir and call the save method"],"metadata":{"id":"kbgmgGMDdJmT"}},{"cell_type":"code","source":["# Save the entire model as a SavedModel.\n","!mkdir -p saved_model\n","# Save the model\n","model.save('saved_model/my_model')"],"metadata":{"id":"0GiUPpYTa9Ov"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Restore the model saved"],"metadata":{"id":"DN1JE3BJde1u"}},{"cell_type":"markdown","source":["When the model is saved using the save method, we can restore and load the model in a new model just calling the load_model. This procedure"],"metadata":{"id":"3Gs5Lz0fdi4W"}},{"cell_type":"code","source":["# Load the saved model\n","new_model = tf.keras.models.load_model('saved_model/my_model')\n","\n","# Check its architecture\n","new_model.summary()"],"metadata":{"id":"KD1PhDLzdWV3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the restored model\n","loss, acc = new_model.evaluate(X_test, y_test, verbose=2)\n","print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"],"metadata":{"id":"qX7q667SeIjj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the predicted probabilities\n","predictions = new_model.predict(X_test)\n","# Calculate the predicted label for test dataset\n","y_preds= predictions > 0.5\n","# Calculate the confussion matrix\n","cm = confusion_matrix(y_test, y_preds)\n","# Plot confussion matrix\n","plot_confusion_matrix(cm, class_names)"],"metadata":{"id":"FGeZAAGxfV0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"muYKLYbx6HMk"},"execution_count":null,"outputs":[]}]}